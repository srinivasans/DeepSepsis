{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from lifelines import CoxPHFitter\n",
    "from datautils.dataset import Dataset\n",
    "from datautils.data import Data\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/32269 [00:00<01:42, 314.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputation mode = mean\n",
      "Processing train data...\n",
      "* Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32269/32269 [01:05<00:00, 488.97it/s]\n",
      "  1%|          | 343/32269 [00:00<00:09, 3427.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32269/32269 [00:07<00:00, 4294.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Unpadding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32269/32269 [00:00<00:00, 147083.08it/s]\n",
      "  1%|          | 36/4034 [00:00<00:11, 358.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val data...\n",
      "* Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4034/4034 [00:07<00:00, 567.59it/s]\n",
      "100%|██████████| 4034/4034 [00:00<00:00, 27668.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4034/4034 [00:00<00:00, 157966.78it/s]\n",
      "  2%|▏         | 75/4033 [00:00<00:05, 745.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Unpadding...\n",
      "Processing test data...\n",
      "* Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4033/4033 [00:06<00:00, 640.42it/s]\n",
      "100%|██████████| 4033/4033 [00:00<00:00, 25029.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4033/4033 [00:00<00:00, 139151.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Unpadding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(\"data/challenge_data\",\n",
    "                    batchSize=100,\n",
    "                    train_ratio=0.8,\n",
    "                    normalize=True,\n",
    "                    padding=False,\n",
    "                    imputeForward=False,\n",
    "                    calculateDelay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32269,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4034,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(4033,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(dataset.train_data.features.keys())[:-2]\n",
    "\n",
    "dataset.train_data.x.shape\n",
    "dataset.val_data.x.shape\n",
    "dataset.test_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create windowing system here\n",
    "T = 6\n",
    "#idx = 10\n",
    "def process_data(d: Data, T: int) -> (pd.DataFrame, np.array):\n",
    "    npa = d.x\n",
    "    target_npa = d.y\n",
    "    \n",
    "    processed = []\n",
    "    labels = []\n",
    "\n",
    "    print(\"* Processing data...\")\n",
    "    for idx in tqdm(range(npa.shape[0])):\n",
    "        if target_npa[idx].sum() == 0:\n",
    "            processed.extend([[row,7,1] for row in npa[idx]])\n",
    "        else:\n",
    "            sepsis_count = 0\n",
    "            for i in range(npa[idx].shape[0]):\n",
    "                t = (T + 1) - sepsis_count\n",
    "                t = t if t >= 1 else 1\n",
    "                s = 1 if t > T else 0\n",
    "                processed.append([npa[idx][i],t,s])\n",
    "                sepsis_count += 1 if target_npa[idx][i][0] == 1 else 0\n",
    "                \n",
    "        labels.extend(target_npa[idx].flatten().tolist())\n",
    "                \n",
    "    return (pd.DataFrame(processed, columns=[\"x\",\"t\",\"s\"]), np.array(labels))\n",
    "# Naive windowing:\n",
    "#             for i in range(df[idx].shape[0]):\n",
    "#                 window = df[idx][i:i+T]\n",
    "#                 matches = np.where(window[:,-1]==1)[0]\n",
    "#                 if matches.size > 0:\n",
    "#                     t = matches[0] + 1\n",
    "#                     s = 0\n",
    "#                 else:\n",
    "#                     t = T + 1\n",
    "#                     s = 1\n",
    "#                 processed.append([df[idx][i][:-1],t,s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/32269 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32269/32269 [00:02<00:00, 13294.76it/s]\n",
      "100%|██████████| 4034/4034 [00:00<00:00, 26516.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████▉| 4021/4033 [00:00<00:00, 20522.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Processing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4033/4033 [00:00<00:00, 20017.36it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = process_data(dataset.train_data, T)\n",
    "X_val, y_val = process_data(dataset.val_data, T)\n",
    "X_test, y_test = process_data(dataset.test_data, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>t</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.7250015421218633, 0.9549845983461365, 0.0,...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.37832799104262854, 0.9549845983461365, -0....</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.7250015421218633, 0.9549845983461365, 0.0,...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.6094436917621183, 0.9549845983461365, 0.0,...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   x  t  s\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  7  1\n",
       "1  [-0.7250015421218633, 0.9549845983461365, 0.0,...  7  1\n",
       "2  [-0.37832799104262854, 0.9549845983461365, -0....  7  1\n",
       "3  [-0.7250015421218633, 0.9549845983461365, 0.0,...  7  1\n",
       "4  [-0.6094436917621183, 0.9549845983461365, 0.0,...  7  1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_s = 1-X_train.s\n",
    "X_train_cph = pd.DataFrame(X_train.x.values.tolist(), columns=columns)\n",
    "X_train_cph[\"s\"] = inverse_s\n",
    "X_train_cph[\"w\"] = (inverse_s * 70) + X_train.s\n",
    "X_train_cph[\"t\"] = X_train.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lifelines/utils/__init__.py:919: ConvergenceWarning: Column FiO2 have very low variance when conditioned on death event present or not. This may harm convergence. This could be a form of 'complete separation'. For example, try the following code:\n",
      "\n",
      ">>> events = df['s'].astype(bool)\n",
      ">>> print(df.loc[events, 'FiO2'].var())\n",
      ">>> print(df.loc[~events, 'FiO2'].var())\n",
      "\n",
      "A very low variance means that the column FiO2 completely determines whether a subject dies or not. See https://stats.stackexchange.com/questions/11109/how-to-deal-with-perfect-separation-in-logistic-regression \n",
      "  warnings.warn(warning_text, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: norm_delta = 0.29762, step_size = 0.0700, ll = -19830176.15702, newton_decrement = 79158.93220, seconds_since_start = 0.9\n",
      "Iteration 2: norm_delta = 0.27390, step_size = 0.0700, ll = -19819483.62577, newton_decrement = 67442.12926, seconds_since_start = 1.9\n",
      "Iteration 3: norm_delta = 0.25249, step_size = 0.0700, ll = -19810373.60302, newton_decrement = 57545.76550, seconds_since_start = 2.8\n",
      "Iteration 4: norm_delta = 0.23304, step_size = 0.0840, ll = -19802600.25375, newton_decrement = 49165.87385, seconds_since_start = 3.7\n",
      "Iteration 5: norm_delta = 0.21177, step_size = 0.1008, ll = -19794688.75476, newton_decrement = 40698.09037, seconds_since_start = 4.6\n",
      "Iteration 6: norm_delta = 0.18886, step_size = 0.1210, ll = -19786899.39487, newton_decrement = 32424.00882, seconds_since_start = 5.5\n",
      "Iteration 7: norm_delta = 0.16463, step_size = 0.1452, ll = -19779532.02312, newton_decrement = 24659.17587, seconds_since_start = 6.4\n",
      "Iteration 8: norm_delta = 0.13955, step_size = 0.1742, ll = -19772895.43073, newton_decrement = 17719.66980, seconds_since_start = 7.4\n",
      "Iteration 9: norm_delta = 0.11429, step_size = 0.2090, ll = -19767262.73166, newton_decrement = 11875.83783, seconds_since_start = 8.4\n",
      "Iteration 10: norm_delta = 0.08969, step_size = 0.2508, ll = -19762819.45201, newton_decrement = 7300.74707, seconds_since_start = 9.5\n",
      "Iteration 11: norm_delta = 0.06671, step_size = 0.3010, ll = -19759618.35801, newton_decrement = 4027.89819, seconds_since_start = 10.6\n",
      "Iteration 12: norm_delta = 0.04633, step_size = 0.3612, ll = -19757559.94952, newton_decrement = 1936.59593, seconds_since_start = 11.5\n",
      "Iteration 13: norm_delta = 0.02944, step_size = 0.4334, ll = -19756414.43158, newton_decrement = 778.95457, seconds_since_start = 12.4\n",
      "Iteration 14: norm_delta = 0.01661, step_size = 0.5201, ll = -19755885.86844, newton_decrement = 247.02076, seconds_since_start = 13.4\n",
      "Iteration 15: norm_delta = 0.00795, step_size = 0.6241, ll = -19755695.83853, newton_decrement = 56.34598, seconds_since_start = 14.3\n",
      "Iteration 16: norm_delta = 0.00298, step_size = 0.7490, ll = -19755647.47192, newton_decrement = 7.90575, seconds_since_start = 15.2\n",
      "Iteration 17: norm_delta = 0.00075, step_size = 0.8987, ll = -19755640.06601, newton_decrement = 0.49597, seconds_since_start = 16.3\n",
      "Iteration 18: norm_delta = 0.00008, step_size = 1.0000, ll = -19755639.57513, newton_decrement = 0.00507, seconds_since_start = 17.3\n",
      "Iteration 19: norm_delta = 0.00000, step_size = 1.0000, ll = -19755639.57006, newton_decrement = 0.00000, seconds_since_start = 18.2\n",
      "Convergence completed after 19 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lifelines.CoxPHFitter: fitted with 1240275 observations, 1220655 censored>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cph = CoxPHFitter(penalizer=0.2)\n",
    "cph.fit(X_train_cph, duration_col='t', event_col='s', weights_col='w', step_size=0.070, show_progress=True, robust=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lifelines.CoxPHFitter: fitted with 1240275 observations, 1220655 censored>\n",
      "      duration col = 't'\n",
      "         event col = 's'\n",
      "       weights col = 'w'\n",
      "         penalizer = 0.2\n",
      "number of subjects = 1240275\n",
      "  number of events = 19620\n",
      "    log-likelihood = -19755639.57\n",
      "  time fit was run = 2019-04-10 21:48:38 UTC\n",
      "\n",
      "---\n",
      "                  coef exp(coef)  se(coef)      z      p  -log2(p)  lower 0.95  upper 0.95\n",
      "HR                0.18      1.20      0.00 204.95 <0.005       inf        0.18        0.18\n",
      "O2Sat            -0.00      1.00      0.00  -1.68   0.09      3.44       -0.00        0.00\n",
      "Temp              0.12      1.13      0.00  99.16 <0.005       inf        0.12        0.13\n",
      "SBP               0.04      1.05      0.00  30.43 <0.005    673.02        0.04        0.05\n",
      "MAP              -0.15      0.86      0.00 -76.72 <0.005       inf       -0.15       -0.14\n",
      "DBP              -0.04      0.96      0.00 -27.04 <0.005    532.51       -0.05       -0.04\n",
      "Resp              0.13      1.14      0.00 159.66 <0.005       inf        0.13        0.13\n",
      "EtCO2            -0.09      0.91      0.00 -25.93 <0.005    489.97       -0.10       -0.09\n",
      "BaseExcess        0.16      1.17      0.00  43.18 <0.005       inf        0.15        0.17\n",
      "HCO3             -0.03      0.97      0.00  -6.86 <0.005     37.12       -0.03       -0.02\n",
      "FiO2             -0.01      0.99      0.01  -0.86   0.39      1.35       -0.02        0.01\n",
      "pH               -0.06      0.94      0.00 -16.63 <0.005    203.79       -0.07       -0.05\n",
      "PaCO2            -0.01      0.99      0.00  -3.48 <0.005     10.97       -0.02       -0.01\n",
      "SaO2              0.10      1.10      0.00  20.38 <0.005    304.35        0.09        0.11\n",
      "AST               0.00      1.00      0.00   0.20   0.84      0.25       -0.01        0.01\n",
      "BUN               0.17      1.19      0.00  59.20 <0.005       inf        0.17        0.18\n",
      "Alkalinephos      0.03      1.03      0.00   6.04 <0.005     29.25        0.02        0.04\n",
      "Calcium          -0.12      0.89      0.00 -45.31 <0.005       inf       -0.12       -0.11\n",
      "Chloride         -0.01      0.99      0.00  -2.31   0.02      5.60       -0.02       -0.00\n",
      "Creatinine        0.01      1.01      0.00   3.97 <0.005     13.74        0.01        0.02\n",
      "Bilirubin_direct  0.05      1.05      0.01   4.78 <0.005     19.14        0.03        0.08\n",
      "Glucose           0.03      1.03      0.00  13.56 <0.005    136.65        0.02        0.03\n",
      "Lactate           0.01      1.01      0.00   1.47   0.14      2.83       -0.00        0.01\n",
      "Magnesium         0.03      1.03      0.00   8.51 <0.005     55.65        0.02        0.03\n",
      "Phosphate        -0.01      0.99      0.00  -2.67   0.01      7.05       -0.02       -0.00\n",
      "Potassium        -0.06      0.94      0.00 -22.71 <0.005    376.93       -0.06       -0.05\n",
      "Bilirubin_total   0.08      1.08      0.00  17.69 <0.005    230.15        0.07        0.09\n",
      "TroponinI        -0.03      0.97      0.01  -3.49 <0.005     11.00       -0.04       -0.01\n",
      "Hct               0.03      1.03      0.01   5.15 <0.005     21.87        0.02        0.04\n",
      "Hgb              -0.04      0.96      0.01  -6.89 <0.005     37.34       -0.06       -0.03\n",
      "PTT               0.04      1.04      0.00   9.07 <0.005     62.93        0.03        0.05\n",
      "WBC               0.07      1.07      0.00  45.33 <0.005       inf        0.06        0.07\n",
      "Fibrinogen        0.16      1.17      0.01  25.13 <0.005    460.45        0.15        0.17\n",
      "Platelets        -0.06      0.94      0.00 -17.98 <0.005    237.72       -0.07       -0.05\n",
      "Age               0.00      1.00      0.00   1.25   0.21      2.24       -0.00        0.00\n",
      "Gender            0.08      1.08      0.00  45.34 <0.005       inf        0.08        0.08\n",
      "---\n",
      "Concordance = 0.64\n",
      "Log-likelihood ratio test = 149073.17 on 36 df, -log2(p)=inf\n"
     ]
    }
   ],
   "source": [
    "#cph.check_assumptions(X_train_cph,show_plots=False,plot_n_bootstraps=0)\n",
    "cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ty, py, threshold=0.5):\n",
    "    print('-'*20)\n",
    "    auc = roc_auc_score(ty, py)\n",
    "    print(f\"AUC = {auc}\")\n",
    "    lst = [1 if i >=0.5 else 0 for i in py]\n",
    "    acc = ((lst == ty).sum() / ty.shape[0]) * 100\n",
    "    print(f\"Accuracy = {acc}\")\n",
    "    c_m = confusion_matrix(ty, np.array(py > threshold).astype(int))\n",
    "    print(c_m)\n",
    "    PPV = c_m[1,1] / (c_m[1,1] + c_m[0,1])\n",
    "    print(f\"PPV/Precision = {PPV}\")\n",
    "    TPR = c_m[1,1] / c_m[1].sum()\n",
    "    print(f\"TPR/Sensitivity/Recall = {TPR}\")\n",
    "    TNR = c_m[0,0] / c_m[0].sum()\n",
    "    print(f\"TNR/Specificity = {TNR}\")\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(df: pd.DataFrame, ty, columns, threshold=0.5):\n",
    "    cph_df = pd.DataFrame(df.x.values.tolist(), columns=columns)\n",
    "    \n",
    "    preds = 1-cph.predict_survival_function(cph_df,times=[6])\n",
    "    \n",
    "    get_metrics(ty, preds, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "--------------------\n",
      "AUC = 0.6330696316140252\n",
      "Accuracy = 66.72044506258693\n",
      "[[815949 402402]\n",
      " [ 10356  11568]]\n",
      "PPV/Precision = 0.027944053916950505\n",
      "TPR/Sensitivity/Recall = 0.5276409414340448\n",
      "TNR/Specificity = 0.669715870057151\n",
      "--------------------\n",
      "Val:\n",
      "--------------------\n",
      "AUC = 0.6354492241246463\n",
      "Accuracy = 66.16481415470365\n",
      "[[100527  50888]\n",
      " [  1318   1562]]\n",
      "PPV/Precision = 0.029780743565300288\n",
      "TPR/Sensitivity/Recall = 0.5423611111111111\n",
      "TNR/Specificity = 0.663917049169501\n",
      "--------------------\n",
      "Test:\n",
      "--------------------\n",
      "AUC = 0.6520365380575449\n",
      "Accuracy = 66.5960416138036\n",
      "[[103256  51272]\n",
      " [  1386   1726]]\n",
      "PPV/Precision = 0.03256726668930903\n",
      "TPR/Sensitivity/Recall = 0.5546272493573264\n",
      "TNR/Specificity = 0.6682025264029819\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\")\n",
    "evaluate(X_train, y_train, columns, threshold=0.5)\n",
    "print(\"Val:\")\n",
    "evaluate(X_val, y_val, columns, threshold=0.5)\n",
    "print(\"Test:\")\n",
    "evaluate(X_test, y_test, columns, threshold=0.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mean Imputation:\n",
    "--------------------\n",
    "AUC = 0.6975819347308856\n",
    "[[30682  6691]\n",
    " [  380   271]]\n",
    "PPV/Precision = 0.0389255960930767\n",
    "TPR/Sensitivity/Recall = 0.4162826420890937\n",
    "TNR/Specificity = 0.820967008268001"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Forward Imputation:\n",
    "--------------------\n",
    "AUC = 0.6725981960102807\n",
    "[[30171  7331]\n",
    " [  259   222]]\n",
    "PPV/Precision = 0.029392294452535415\n",
    "TPR/Sensitivity/Recall = 0.46153846153846156\n",
    "TNR/Specificity = 0.8045170924217375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
